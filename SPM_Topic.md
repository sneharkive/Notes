**1. Legacy Software:**
Old software systems that are still in use but built with outdated technology or design, often hard to maintain or update.

**2. Software Evolution:**
The process of modifying and updating software after delivery to correct faults, improve performance, or adapt to a changed environment.

**3. Purpose to Study Software Engineering:**
To learn systematic, disciplined approaches for designing, developing, testing, and maintaining high-quality software efficiently.

**4. Egoless Team Structure (for software development):**
A structure where all members collaborate equally, focus on solving problems rather than personal credit, and encourage open peer review.

**5. Who Carries RA Fees (Requirement Analysis):**
Usually, **the client bears the cost**, since requirement analysis is part of the project’s development cost.

**6. Example of Dynamic Model of Real-Time Software Design:**
**State transition diagrams** or **activity diagrams** showing system behavior changes in response to events (e.g., traffic light control system).

**7. Regression Test:**
Testing done after modifications to ensure new code changes haven’t broken existing functionality.

**8. Example of Brute Force Debugging Technique:**
Using **print statements** or **manual code inspection** throughout the program to locate errors without using debugging tools.

**9. Features of `goto` Statement and Its Significance:**

* Transfers control unconditionally to a labeled statement.
* Can make code hard to read (spaghetti code), hence rarely used.
* Useful in breaking deeply nested loops or error handling in low-level programming.

**10. Test Coverage Criteria:**
Metrics to measure how much of the software code is tested — e.g.,

* **Statement coverage**
* **Branch coverage**
* **Path coverage**
* **Condition coverage**

---



**11. Is Testing a Process or Phase or Function:**
Testing is a **process** — a systematic activity performed during the **testing phase** to ensure software quality and correctness.

**12. Data-Oriented Decomposition:**
Breaking down a system based on **data structures** rather than functions — each module focuses on managing specific data.

**13. Objectives of High-Level Software Design:**

* Define overall system architecture.
* Identify major modules and their relationships.
* Ensure system scalability, maintainability, and performance.

**14. Decomposition in Software Engineering:**
The process of **dividing a complex system into smaller, manageable modules** to simplify development and maintenance.

**15. Define Software Projects:**
A **temporary, planned effort** to develop or modify software within defined scope, time, and cost constraints.

**16. Traditional vs Software Process (Cost & Time):**

* **Traditional Process:** Fixed, linear, and time-consuming (e.g., Waterfall).
* **Software Process:** Iterative and adaptive, reduces cost and time through feedback and flexibility (e.g., Agile).

**17. Types of Software Products:**

* **Application Software:** Performs specific tasks for users (e.g., MS Word, browsers).
* **System Software:** Supports system operations (e.g., OS, compilers).

**18. Abstraction:**
The process of **hiding unnecessary details** and showing only essential features of a system or object.

**19. Interface Design:**
Specifies how system components or users **interact** — defining inputs, outputs, and communication between modules or with users.

**20. Software Rejuvenation:**
The process of **cleaning and refreshing long-running software** to prevent failures caused by resource leaks or software aging.

---



**21. Pilot Testing:**
Testing a complete system on a **small scale or limited users** before full deployment to detect issues in a real environment.

**22. Meta-Model:**
A **model of models** that defines the rules and structure for creating specific models (e.g., UML meta-model defines UML elements).

**23. Win-Win Spiral Model:**
An extension of the spiral model where **all stakeholders negotiate “win-win” conditions** at each phase before proceeding.

**24. Software Project Manager:**
A person responsible for **planning, organizing, leading, and controlling** software projects to meet time, cost, and quality goals.

**25. Software Design Model:**
A **representation of the system’s architecture**, components, interfaces, and data flow used to guide implementation.

**26. Interface Design:**
Defines how **modules, components, or users** interact through inputs, outputs, and communication channels.

**27. SCM (Software Configuration Management):**
A process to **control and manage software changes**, versions, and configurations to maintain integrity over time.

**28. Software Reliability, Availability, Maintainability:**

* **Reliability:** Probability software works without failure.
* **Availability:** Probability software is operational when needed.
* **Maintainability:** Ease of correcting or updating software.

**29. Defect:**
A **flaw or imperfection** in software that causes incorrect or unexpected behavior.

**30. Reliability – Metrics, Tools, Price:**

* **Metrics:** MTBF (Mean Time Between Failures), Failure Rate.
* **Tools:** Sentry, Bugzilla, Reliability Workbench.
* **Price:** Depends on system size and tool license (varies).

**31. Alpha Testing / Beta Testing:**

* **Alpha:** In-house testing by developers/testers before release.
* **Beta:** Real-world testing by end users to find undetected issues.

**32. Standard of Software Product:**
Set of **quality guidelines and benchmarks** ensuring consistency (e.g., ISO 9126, IEEE standards).

**33. Six Sigma:**
A **quality improvement methodology** aimed at reducing defects to near zero (3.4 defects per million opportunities).

**34. Pattern:**
A **reusable solution** to a common software design problem (e.g., Singleton, Observer pattern).

**35. Structured Analysis Tool:**
Tools used for **system modeling** — e.g., **DFD (Data Flow Diagram)**, **ER Diagram**, **Structure Charts**.

**36. Negative and Positive Test Cases:**

* **Positive:** Verify software works as expected with valid input.
* **Negative:** Check behavior with invalid or unexpected input.

**37. Fault vs Failure vs Error:**

* **Error:** Human mistake in coding/design.
* **Fault (Bug):** Defect in the code caused by an error.
* **Failure:** When a fault causes incorrect system behavior.

**38. Stub:**
A **dummy module** that simulates a lower-level component during top-down integration testing.

**39. Modular Design:**
Dividing software into **independent, reusable modules** to improve maintainability and scalability.

**40. Data Dictionary:**
A **repository containing definitions of all data elements**, their types, formats, and relationships used in the system.

---
---








# Details

---

### **1. Legacy Software**

Legacy software refers to **old, existing software systems** that are still in use but built with **outdated technology** or design methods.
**Features:**

* Hard to modify or maintain.
* Poor documentation.
* Still essential for business operations.
  **Example:** Old banking systems built in COBOL.

---

### **2. Software Evolution**

Software evolution is the **continuous process of modifying software** after its initial release to fix bugs, improve performance, or adapt to new requirements.
**Phases:**

1. Development
2. Operation
3. Maintenance
4. Retirement
   **Goal:** Extend software’s life and value.

---

### **3. Purpose to Study Software Engineering**

The main purposes are:

* To **develop high-quality software** systematically.
* To **reduce development cost and time**.
* To **apply engineering principles** to software design.
* To **ensure maintainability, reliability, and scalability**.
  It turns coding into a **disciplined process** rather than a trial-and-error activity.

---

### **4. Egoless Scheme Structure (in Software Development)**

An **egoless structure** means **team-based software development** where no single member dominates.

* Every member’s idea is respected.
* Focus is on **code quality**, not personal credit.
* Encourages collaboration, peer review, and open communication.
  **Goal:** Reduce conflicts and improve productivity.

---

### **5. Who Carries RA Fees? (Requirement Analysis)**

The **requirement analyst or system analyst** carries out and manages **Requirement Analysis (RA)**.
**Responsibilities:**

* Gather user needs.
* Analyze feasibility.
* Document Software Requirement Specification (SRS).
* Communicate with clients and developers.

---

### **6. Example of Dynamic Model of Real-Time Software Design**

A **dynamic model** represents the **behavior of a system over time**.
**Example:**

* **State Transition Diagram (STD)** or **UML Sequence Diagram**.
  In real-time systems (like flight control), these models show how the system **responds to events** dynamically.

---

### **7. Regression Test**

Regression testing checks whether **new code changes** have affected **existing functionalities**.
**Goal:** Ensure stability after modifications, updates, or bug fixes.
**Example:** After adding a new feature, old modules are re-tested.

---

### **8. Example of Brute Force Debugging Technique**

Brute force debugging involves **checking all possible causes** of an error without a specific strategy.
**Example:**

* Printing all variable values (using `print` statements) throughout the code to find where it goes wrong.
  **Disadvantage:** Time-consuming and inefficient.

---

### **9. Features of GOTO Statement and Its Significance**

**GOTO statement** transfers program control to a labeled statement.
**Features:**

* Used for **unconditional jumps**.
* Simplifies small programs but **makes code hard to read**.
  **Significance:**
* Used in low-level programming or error handling.
  **Example:**

```c
if (error) goto cleanup;
```

---

### **10. Test Coverage Criteria**

Measures **how much of the software has been tested**.
**Types:**

1. **Statement Coverage:** All statements executed.
2. **Branch Coverage:** All decision outcomes tested.
3. **Path Coverage:** All execution paths tested.
   **Purpose:** Ensure thorough testing and detect untested parts of code.

---

### **11. Is Testing a Process, Phase, or Function?**

Testing is a **process**, not just a phase.

* It spans all phases: design, development, and deployment.
* It’s a **function** of quality assurance to ensure correctness.
  **Conclusion:** Testing is both a **process and function** within the SDLC.

---

### **12. Data-Oriented Decomposition**

Breaking a system into **modules based on data structures or data flow**.
**Example:** In a payroll system, modules may be grouped by data — employee data, salary data, etc.
**Benefit:** Improves maintainability and clarity of data handling.

---

### **13. Objectives of High-Level Software Design**

* Define **software architecture** (modules, relationships, data flow).
* Ensure **modularity** and **low coupling**.
* Provide a **blueprint for detailed design**.
* Ensure the design fulfills **functional and non-functional requirements**.

---

### **14. Meaning of Decomposition in Software Engineering**

Decomposition means **dividing a complex system** into **smaller, manageable parts** or modules.
**Purpose:**

* Simplify design and understanding.
* Allow parallel development.
* Improve testing and maintenance.
  **Example:** Breaking a hospital management system into registration, billing, and report modules.

---

### **15. Define Software Projects**

A software project is a **planned set of activities** aimed at developing or maintaining a software product.
**Features:**

* Has defined goals, scope, and timeline.
* Requires resources (team, tools, time, cost).
  **Example:** Developing a school management system.

---

### **16. Traditional vs Software Process (Cost and Time Focus)**

| **Aspect**          | **Traditional Process**       | **Software Process**                    |
| ------------------- | ----------------------------- | --------------------------------------- |
| **Nature**          | Manual and sequential         | Iterative and automated                 |
| **Cost & Time**     | High, due to rework and delay | Lower, due to reuse and better planning |
| **Change Handling** | Rigid                         | Flexible                                |
| **Example**         | Waterfall Model               | Agile, Spiral Model                     |

---

### **17. Types of Software Products**

**1. Application Software:**

* Designed for end users to perform specific tasks.
* Examples: MS Word, Photoshop, Banking Apps.

**2. System Software:**

* Provides platform for running applications.
* Examples: Operating Systems, Compilers, Drivers.

---

### **18. Meaning of Abstraction**

Abstraction is the process of **hiding unnecessary details** and showing only essential features.
**Example:**

* A car’s steering hides the internal engine mechanism.
* In OOP: Classes abstract real-world entities.
  **Benefit:** Reduces complexity and enhances reusability.

---

### **19. Define Interface Design**

Interface design defines **how different modules, systems, or users interact** with each other.
**Types:**

* **User Interface (UI):** How users interact.
* **System Interface:** How components exchange data.
  **Goal:** Ensure simplicity, consistency, and usability.

---

### **20. Define Software Rejuvenation**

Software rejuvenation means **restoring software performance by cleaning and refreshing resources**.
**Used In:** Long-running systems (servers, databases).
**Methods:**

* Restarting applications periodically.
* Clearing caches and memory leaks.
  **Purpose:** Prevent failures due to software aging.

---


### **21. Pilot Testing**

Pilot testing is a **trial run** of a system or product before full deployment.
**Purpose:** To identify problems in a **controlled, small-scale environment**.
**Steps:**

1. Select limited users.
2. Test system in real environment.
3. Collect feedback and fix issues.
   **Example:** A new hospital management software tested in one hospital branch before rollout to all.

---

### **22. Meta-Model**

A **meta-model** is a model that **defines rules and structure** for creating other models.

* It describes **how models are built**, not the actual model itself.
  **Example:** UML meta-model defines how UML diagrams (like class or activity diagrams) should be structured.
  **Purpose:** Ensures standardization and consistency among modeling tools.

---

### **23. Win-Win Spiral Model**

Developed by Barry Boehm, the **Win-Win Spiral Model** extends the Spiral Model by ensuring all stakeholders achieve a “win”.
**Phases:**

1. Identify stakeholders and their objectives.
2. Resolve conflicts for mutual satisfaction.
3. Develop and validate the product iteratively.
   **Advantages:** Balances developer, user, and business goals; reduces risk.

---

### **24. Software Project Manager**

A **Software Project Manager (SPM)** is responsible for **planning, executing, and controlling** software projects.
**Responsibilities:**

* Define scope and goals.
* Schedule tasks and allocate resources.
* Monitor progress, manage risks, and communicate with stakeholders.
  **Skills Required:** Leadership, technical expertise, problem-solving, communication.

---

### **25. Software Design Model**

A **software design model** represents **how the software will be built** to meet requirements.
**Components:**

1. **Architectural Design:** Structure of modules.
2. **Detailed Design:** Internal logic of each module.
3. **Interface Design:** Interaction between components.
   **Purpose:** Serves as a blueprint for developers to implement the system.

---

### **26. Interface Design**

Defines **how components, systems, or users interact**.
**Types:**

* **User Interface (UI):** Focuses on user interaction (buttons, screens).
* **System Interface:** Data exchange between modules or systems.
  **Principles:** Simplicity, consistency, feedback, visibility.
  **Goal:** Ensure usability and communication efficiency.

---

### **27. SCM (Software Configuration Management)**

SCM is a process to **track and control software changes** throughout development.
**Main Activities:**

1. **Configuration Identification:** Labeling items (code, docs).
2. **Version Control:** Managing multiple versions.
3. **Change Control:** Approving and recording modifications.
4. **Status Accounting:** Reporting status of items.
5. **Auditing:** Ensuring compliance with procedures.
   **Tools:** Git, SVN, CVS.

---

### **28. Software Reliability, Availability, Maintainability**

* **Reliability:** Probability that software performs without failure for a specific time.
  → Example: 99.9% reliable means very few crashes.
* **Availability:** Percentage of time the system is operational.
  [
  \text{Availability} = \frac{MTBF}{MTBF + MTTR}
  ]
* **Maintainability:** Ease of modifying or fixing defects in software.
  **Goal:** Ensure system stability, continuous operation, and easy repair.

---

### **29. Defect**

A **defect** is a **flaw or imperfection** in software that causes incorrect or unexpected behavior.
**Causes:**

* Coding mistakes.
* Design errors.
* Misunderstood requirements.
  **Detected During:** Testing, code review, or real-world use.
  **Example:** Login button not responding when clicked.

---

### **30. Reliability — Metrics, Tools, Price**

**Metrics:**

* **MTTF (Mean Time To Failure):** Average time until the first failure.
* **MTTR (Mean Time To Repair):** Average time to fix a failure.
* **MTBF (Mean Time Between Failures):** MTTF + MTTR.
* **Failure Rate:** Number of failures per time unit.

**Tools:**

* JMeter, LoadRunner, ReliSoft, Bugzilla.

**Price (Cost of Reliability):**
Includes cost of:

* Prevention (quality assurance).
* Detection (testing).
* Correction (bug fixing).

---

### **31. Alpha Testing & Beta Testing**

**Alpha Testing:**

* Conducted internally by developers/testers.
* In a controlled environment.
* Detects major bugs before release.

**Beta Testing:**

* Conducted by actual users in real environments.
* Provides feedback for improvement.
  **Example:** Mobile app tested by selected users before global release.

---

### **32. Standard of Software Product**

Software standards define **quality benchmarks** for development and evaluation.
**Examples:**

* **ISO/IEC 9126:** Software quality model (functionality, reliability, usability, efficiency, maintainability, portability).
* **IEEE 830:** SRS documentation standard.
  **Purpose:** Ensure uniformity, maintainability, and interoperability.

---

### **33. Six Sigma**

Six Sigma is a **data-driven quality improvement process** aiming for near perfection (3.4 defects per million).
**Phases (DMAIC):**

1. Define
2. Measure
3. Analyze
4. Improve
5. Control
   **Goal:** Reduce defects, improve efficiency, and enhance customer satisfaction.

---

### **34. Pattern**

A **design pattern** is a **reusable solution** to a recurring software design problem.
**Types:**

1. **Creational:** Object creation (Singleton, Factory).
2. **Structural:** Object composition (Adapter, Bridge).
3. **Behavioral:** Object communication (Observer, Strategy).
   **Benefits:** Reduces design time, promotes reuse and best practices.

---

### **35. Structured Analysis Tools**

Used to **model system processes and data flow**.
**Tools:**

1. **DFD (Data Flow Diagram):** Represents data movement.
2. **ER Diagram:** Models entities and relationships.
3. **Structure Chart:** Shows module hierarchy.
4. **Decision Tables:** Represents logic systematically.
   **Purpose:** Visualize system functionality and data dependencies.

---

### **36. Negative and Positive Test Cases**

**Positive Test Cases:** Test with **valid input** → expected output.
Example: Correct username and password → successful login.

**Negative Test Cases:** Test with **invalid input** → error message.
Example: Blank password → “Password required.”
**Purpose:** Ensure software behaves correctly in both cases.

---

### **37. Fault vs Failure vs Error**

| **Term**        | **Meaning**                                 | **Example**                 |
| --------------- | ------------------------------------------- | --------------------------- |
| **Error**       | Human mistake during design or coding       | Wrong formula in code       |
| **Fault (Bug)** | Defect in code caused by an error           | Incorrect logic in function |
| **Failure**     | System behaves incorrectly during execution | App crashes during login    |

**Relation:** Error → Fault → Failure.

---

### **38. Stub**

A **stub** is a **dummy module** used during **top-down integration testing** to simulate missing components.
**Purpose:** To test higher-level modules before all lower modules are ready.
**Example:** Stub for payment module returning “Success” when actual payment API is not implemented.

---

### **39. Modular Design**

Modular design divides software into **independent, self-contained modules**, each handling a specific task.
**Advantages:**

* Easy to develop, test, and maintain.
* Promotes code reuse.
* Simplifies debugging.
  **Example:** A website divided into modules like login, database, and reports.

---

### **40. Data Dictionary**

A **data dictionary** is a **central repository** that describes **data elements** used in a system.
**Includes:**

* Field names, data types, sizes, and constraints.
* Relationships between data.
  **Purpose:**
* Maintain consistency.
* Support documentation.
* Help developers understand data flow.
  **Example:** Student_ID → Integer(10), Name → Varchar(50).

---